{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zh19980811/Automatic-Text-Processing-and-Image-Processing-itmo/blob/main/Task_2_Programmers_EN_students_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_ST0GfO97y"
      },
      "source": [
        "# Information Retrieval\n",
        "\n",
        "Let's download the classical data set, i.e. the CRANFIELD text set on aeronautics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHflLH2APAHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75fbb8c-0e48-4a31-e954-771eacbb9bd6"
      },
      "source": [
        "! wget -q http://ir.dcs.gla.ac.uk/resources/test_collections/cran/cran.tar.gz\n",
        "! tar -xvf cran.tar.gz\n",
        "! rm cran.tar.gz*"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cran.all.1400\n",
            "cran.qry\n",
            "cranqrel\n",
            "cranqrel.readme\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYuND83cPR5D"
      },
      "source": [
        "We take queries only (we will consider queries as documents)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6owW-L7zhJws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56112533-7ccb-48d7-f57f-a3451a472677"
      },
      "source": [
        "! grep -v \"^\\.\" cran.qry > just.qry\n",
        "! head -3 just.qry"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what similarity laws must be obeyed when constructing aeroelastic models\r\n",
            "of heated high speed aircraft .\r\n",
            "what are the structural and aeroelastic problems associated with flight\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZbUb6FmQxr1"
      },
      "source": [
        "We combine  multi-string queries into one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBaV3xeQiUam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66a7dbb-1849-4cca-ecbf-1e79f3bfc9a1"
      },
      "source": [
        "raw_query_data = [line.strip() for line in open(\"just.qry\", \"r\").readlines()]\n",
        "query_data = [\"\"]\n",
        "\n",
        "for query_part in raw_query_data:\n",
        "  query_data[-1] += query_part + \" \"\n",
        "  if query_part.endswith(\".\"):\n",
        "    query_data.append(\"\")\n",
        "\n",
        "query_data[:2] #Let's output the couple of documents as an example"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft . ',\n",
              " 'what are the structural and aeroelastic problems associated with flight of high speed aircraft . ']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLFq_6lBki3S"
      },
      "source": [
        "### Let's make queries to our documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3sgHjWkjjR1"
      },
      "source": [
        "QUERIES = ['yawed cylinder']"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQMdH0HSkoJg"
      },
      "source": [
        "## Boolean retrieval\n",
        "Let's represent each document as a \"bitmask\": that is a vector with a dimensionality equal to the vocabulary size, which has 1 at every position if the document contains the corresponding term; and 0 if it does not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhrI18rZSLLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43db0754-4b37-4f87-c891-775058f95a08"
      },
      "source": [
        "# in different versions the answer could also differ, therefore it's important to have the same version\n",
        "! pip install -q scikit-learn==0.22.2.post1"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 417, in run\n",
            "    _, build_failures = build(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 320, in build\n",
            "    wheel_file = _build_one(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 194, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 241, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 36, in getlines\n",
            "    def getlines(filename, module_globals=None):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbTOdsHIknD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca857a74-4101-4d62-d41f-391f08fae21d"
      },
      "source": [
        "from  sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "encoder = CountVectorizer(binary=True)\n",
        "encoded_data = encoder.fit_transform(query_data)\n",
        "encoded_queries = encoder.transform(QUERIES)\n",
        "list(encoder.vocabulary_)[:3]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'similarity', 'laws']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUdwKDKSTjdD"
      },
      "source": [
        "Let's look at the representation of the first sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXEmXErylJdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38412658-6d7e-49b3-e04e-d16e7695a080"
      },
      "source": [
        "id2term = {idx: term for term, idx in encoder.vocabulary_.items()}\n",
        "non_zero_values_ids = encoded_data[0].nonzero()[1]\n",
        "\n",
        "terms = [id2term[idx] for idx in non_zero_values_ids]\n",
        "terms"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what',\n",
              " 'similarity',\n",
              " 'laws',\n",
              " 'must',\n",
              " 'be',\n",
              " 'obeyed',\n",
              " 'when',\n",
              " 'constructing',\n",
              " 'aeroelastic',\n",
              " 'models',\n",
              " 'of',\n",
              " 'heated',\n",
              " 'high',\n",
              " 'speed',\n",
              " 'aircraft']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8wdS9XiVwb2"
      },
      "source": [
        "It's fine.\n",
        "\n",
        "## Task 0\n",
        "\n",
        "Now for each query from `QUERIES` let's find the nearest document from `query_data` according to the Jaccard similarity index. There are more effictive solutions to do it, but your task is to realize the algorithm computing the Jaccard index and then apply it to our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u31WuBYAUWt2"
      },
      "source": [
        "from numpy.lib.arraysetops import union1d\n",
        "import numpy as np\n",
        "\n",
        "def jaccard_sim(vector_a: np.array, vector_b: np.array) -> float:\n",
        "  \"\"\"\n",
        "    Similarity or Jaccard similarity index: the ratio of the intersection cardinality to the union cardinality\n",
        "  \"\"\"\n",
        "  # your code here\n",
        "  J = np.logical_and(vector_a, vector_b).sum() / np.logical_or(vector_a, vector_b).sum()\n",
        "  return J\n",
        "\n",
        "#jaccard_sim(np.array([1, 0, 1, 0, 1]), np.array([0, 1, 1, 1, 1]))\n",
        "#Check that the function works correctly\n",
        "assert jaccard_sim(np.array([1, 0, 1, 0, 1]), np.array([0, 1, 1, 1, 1])) == 0.4"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYfQksWrOR1G"
      },
      "source": [
        "## Task 1\n",
        "Now using the code below find the most similar documents for each query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4okpFpA6OAQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73cc7a5c-aa15-4c0d-ca52-527591cac84d"
      },
      "source": [
        "for q_id, query in enumerate(encoded_queries):\n",
        "  # bring to the required datatype\n",
        "  query = query.todense().A1\n",
        "  docs = [doc.todense().A1 for doc in encoded_data]\n",
        "  # calculate the Jaccard index\n",
        "  id2doc2similarity = [(doc_id, doc, jaccard_sim(query, doc)) for doc_id, doc in enumerate(docs)]\n",
        "  # sort according to it\n",
        "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
        "  # output 3 most similar documents for each query\n",
        "  for closest_id, _, sim in closest[:3]:\n",
        "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: compressibility transformation.\n",
            "FOUND:\n",
            "    20\t0.13\twhy does the compressibility transformation fail to correlate the high speed data for helium and air . \n",
            "    0\t0.00\twhat similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft . \n",
            "    1\t0.00\twhat are the structural and aeroelastic problems associated with flight of high speed aircraft . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Fh8RdvOrAD"
      },
      "source": [
        "We see that some texts intersecting with the query only in insignificant terms have a high Jaccard index (that is our ranking function).\n",
        "\n",
        "# VSM\n",
        "\n",
        "Now we are going to do similar calculations, but using tf-idf and cosine distance. To practice we make everything \"manually\", but in \"real life\" it's better to use existing effective solutions, e.g., cosine distance from scipy library."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QUERIES = ['yawed cylinder']  # fix"
      ],
      "metadata": {
        "id": "ItrKhV6MzM3W"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmpKMI08E2iO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25905552-78fb-4fad-dcf5-eb8d820623b6"
      },
      "source": [
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Advice: we highly recommend to check what tf-idf vectorizer\n",
        "# is able to do, and change its parameters\n",
        "\n",
        "tfidf_encoder = TfidfVectorizer()\n",
        "tfidf_encoded_data = tfidf_encoder.fit_transform(query_data)\n",
        "tfidf_encoded_queries = tfidf_encoder.transform(QUERIES)\n",
        "\n",
        "list(tfidf_encoder.vocabulary_)[:3]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'similarity', 'laws']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHTzIjfNRHj2"
      },
      "source": [
        "## Task 2\n",
        "Realize the cosine distance computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCfgR6xEPeDn"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_distance(vector_a: np.array, vector_b: np.array) -> float:\n",
        "    \"\"\"\n",
        "    Cosine distance is 1 minus the ratio of the dot product\n",
        "    and the product of L2-norm (hint: there are such norms in numpy)\n",
        "    \"\"\"\n",
        "\n",
        "    dot_product = np.dot(vector_a, vector_b)\n",
        "\n",
        "    norm_a = np.linalg.norm(vector_a, ord=2)\n",
        "    norm_b = np.linalg.norm(vector_b, ord=2)\n",
        "\n",
        "    if norm_a == 0 or norm_b == 0:\n",
        "        return 1\n",
        "    cosine_similarity = dot_product / (norm_a * norm_b)\n",
        "\n",
        "    distance = 1 - cosine_similarity\n",
        "    return distance\n",
        "\n",
        "\n",
        "assert np.isclose(cosine_distance(np.array([1, 0, 1, 1, 1]), np.array([0, 0, 1, 0, 0])), 0.5)\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHsaHoORlEC"
      },
      "source": [
        "\n",
        "Now let's find the nearset documents to the query according to the cosine distance between the document vector and the query representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIZJRBKQQR1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568d54b9-93f7-4bf9-fcf4-1c67c2dbc775"
      },
      "source": [
        "for q_id, query in enumerate(tfidf_encoded_queries):\n",
        "\n",
        "  # bring to the required datatype\n",
        "  query = query.todense().A1\n",
        "  docs = [doc.todense().A1 for doc in tfidf_encoded_data]\n",
        "  # Cosine distance\n",
        "  id2doc2similarity = [(doc_id, doc, cosine_distance(query, doc)) \\\n",
        "                       for doc_id, doc in enumerate(docs)]\n",
        "  # sort according to it\n",
        "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=False)\n",
        "\n",
        "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
        "\n",
        "  for closest_id, _, sim in closest[:3]:\n",
        "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: yawed cylinder\n",
            "FOUND:\n",
            "    60\t0.56\tdoes there exist a closed-form expression for the local heat transfer around a yawed cylinder . \n",
            "    61\t0.75\thow far around a cylinder and under what conditions of flow,  if any, is the velocity just outside of the boundary layer a linear function of the distance around the cylinder . \n",
            "    213\t0.81\twhat is the effect on cylinder buckling of a circumferential stress system that varies in the axial direction . \n"
          ]
        }
      ]
    }
  ]
}